seed = 12

[model]
booster = "gbtree"
n_estimators = 4000
early_stopping_rounds = 3999
n_jobs = 1
tree_method = "hist"
device = "cuda"
use_label_encoder = false
colsample_bytree = 0.5842449626479825
gamma = 0
lambda = 5.161288900458195
learning_rate = 0.007878010800009412
max_depth = 9
min_child_weight = 0.11643475612478484
subsample = 0.7652350726366343

[fit]
verbose = true

[data]
seed = 0
path = ":data/delivery-eta"
cache = true
split = "random-0"
cat_policy = "ordinal"
