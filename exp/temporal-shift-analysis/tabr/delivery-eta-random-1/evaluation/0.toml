seed = 0
patience = 16
n_epochs = -1
causal = false
batch_size = 1024
context_size = 96

[model]
d_main = 128
context_dropout = 0.47157906367491187
d_multiplier = 2.0
encoder_n_blocks = 0
predictor_n_blocks = 1
mixer_normalization = "auto"
dropout0 = 0.15138941566756456
dropout1 = 0.0
normalization = "LayerNorm"
activation = "ReLU"

[optimizer]
type = "AdamW"
lr = 3.735926556144327e-05
weight_decay = 0.000876973866037529

[data]
seed = 0
path = ":data/delivery-eta"
cache = true
split = "random-1"
cat_policy = "ordinal"
num_policy = "identity"
